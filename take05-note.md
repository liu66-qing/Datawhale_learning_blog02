## **第 4 章 卷积神经网络（CNN）**

卷积神经网络（Convolutional Neural Networks, CNN）是一类针对结构化数据（尤其是图像）而设计的深度神经网络架构。它以**局部感受野（local receptive field）**、**参数共享（parameter sharing）**和**下采样（downsampling）**为核心思想，通过层级化提取特征，极大地提升了计算效率和泛化能力。

CNN 广泛应用于 **图像分类、目标检测、语义分割、视觉生成**等任务，甚至延伸到自然语言处理、棋类决策等领域。

------

### **4.1 图像表示与输入格式**

在计算机视觉任务中，图像被表示为**三维张量**（tensor），其维度结构为：

[
 H \times W \times C
 ]

- (H)：高度（Height）
- (W)：宽度（Width）
- (C)：通道数（Channel）

对于彩色图像，常用 **RGB 色彩模型**，即 (C = 3)，分别对应红（R）、绿（G）、蓝（B）三个通道。对于灰度图像，(C = 1)。

例如：一个 (100 \times 100 \times 3) 的彩色图像，表示为一个包含 30,000 个数值的张量。

**全连接（Fully Connected）输入方式的缺陷：**

直接将图像拉平为一个向量（如 (100 \times 100 \times 3 = 30,000) 维向量），输入到全连接层会导致：

- 参数数量急剧增加，计算复杂度高
- 容易过拟合
- 无法利用图像的空间结构（局部相关性）

例如：若第一层有 (1000) 个神经元，则需要 (30,000 \times 1000 = 3 \times 10^{7}) 个权重。

这促使我们引入 **卷积层** 来充分利用图像的局部特性。

------

### **4.2 核心观察与简化方法**

#### **观察 1：模式检测局限于局部区域**

在图像识别中，许多重要的模式（例如边缘、角点、纹理、形状）存在于局部区域。比如识别“鸟”只需要局部识别鸟嘴、眼睛、羽毛等特征，而不需要整个图像的全局信息。

因此，卷积神经网络引入 **感受野（Receptive Field）**，每个神经元只负责感知输入的局部区域，而非整张图像。

------

#### **简化 1：局部感受野**

感受野是卷积神经元关注的局部区域，其大小由 **卷积核（Kernel）** 决定。
 卷积核通常为 (3 \times 3)、(5 \times 5)、(7 \times 7) 等，深度等于输入通道数。

例如：

- 对于彩色图像：卷积核大小 (3 \times 3 \times 3)
- 对于灰度图像：卷积核大小 (3 \times 3 \times 1)

**优势：**

- 降低参数数量（局部连接权重远小于全连接）
- 保留空间结构

------

#### **观察 2：平移不变性**

相同模式可能出现在图像不同位置，例如鸟嘴可能位于左上角、中间或右下角。
 因此网络需要具备 **平移不变性（Translation Invariance）**，即相同的模式在不同位置被检测到。

------

#### **简化 2：参数共享**

同一卷积核（滤波器）在整个输入图像上滑动（卷积操作），使不同位置的神经元共享相同的权重参数。

**公式：**
 [
 y_{i,j} = \sigma\left( \sum_{m=0}^{k-1} \sum_{n=0}^{k-1} w_{m,n} \cdot x_{i+m,j+n} + b \right)
 ]

其中：

- (w_{m,n})：卷积核权重
- (b)：偏置
- (\sigma)：激活函数
- (x_{i,j})：输入图像像素

**优势：**

- 极大减少参数数量
- 提升特征检测的一致性
- 引入平移不变性

**滤波器（Filter / Kernel）**：共享权重的集合，对应一种特定的模式检测器（如边缘、斜线、纹理）。

------

#### **观察 3：下采样对模式检测无影响**

下采样（Pooling）通过压缩空间分辨率减少计算量，同时保留关键信息。例如，最大池化（Max Pooling）保留局部最大值，从而保留显著特征。

------

#### **简化 3：汇聚（Pooling）**

常见方式：

- **最大池化（Max Pooling）**：取局部窗口最大值
- **平均池化（Average Pooling）**：取局部窗口平均值

**作用：**

- 减少特征图尺寸，降低计算复杂度
- 提高特征的平移不变性
- 控制过拟合

------

### **4.3 卷积神经网络结构**

典型 CNN 模块包含：

1. **卷积层（Convolutional Layer）**：提取局部特征
2. **激活函数（Activation Function）**：引入非线性，例如 ReLU
3. **汇聚层（Pooling Layer）**：降采样
4. **全连接层（Fully Connected Layer）**：整合特征，完成分类

一个典型结构：
 [
 \text{Input} \to \text{[Conv + ReLU]}^n \to \text{Pooling} \to \text{Fully Connected} \to \text{Softmax}
 ]

------

### **4.4 特征图（Feature Map）**

每个卷积核滑动生成一个特征图，表示某一特定模式在整个图像的响应强度。多个卷积核产生多个特征图，构成下一层输入的多通道特征图。

例如：
 输入：(H \times W \times 3)
 卷积核：(k) 个 (3 \times 3 \times 3)
 输出特征图：(H' \times W' \times k)

------

### **4.5 卷积核堆叠与感受野扩展**

连续卷积层叠加能够逐渐扩大感受野，使网络能够检测更大尺度的模式。

例如：

- 第 1 层：(3 \times 3) 感受野
- 第 2 层：覆盖 (5 \times 5) 区域
- 更深层：感受野逐渐扩大

因此，即使单层卷积核较小，深层卷积网络也能捕捉到全局信息。

------

### **4.6 CNN 在围棋中的应用**

以 AlphaGo 为例：

- 输入：围棋棋盘状态，形如 (19 \times 19 \times 48) 张量（48 个通道为不同特征平面）
- 卷积网络提取局部棋型特征
- 输出：预测下一步落子位置，形式为分类任务（每个落子位置为一个类别）

**核心原因**：
 围棋棋盘具有类似图像的局部结构和空间平移不变性，因此 CNN 能有效捕捉局部模式并做全局决策。
